{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30929cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DATA LOADING\n",
      "Shape: (53199, 98)\n",
      "Columns: 98\n",
      "Expected: (53199, 98)\n",
      "\n",
      "'time[s]' found with 14160 missing values\n",
      "New shape: (53199, 97)\n",
      "\n",
      "Timestamp column: 'timestamp'\n",
      "Timestamp missing values: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv('data/raw/original_data.csv')  # UPDATE THIS PATH\n",
    "\n",
    "# Reset index if timestamp is index\n",
    "if 'timestamp' not in df.columns:\n",
    "    df = df.reset_index()\n",
    "\n",
    "print(\"STEP 1: DATA LOADING\")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"Expected: (53199, 98)\")\n",
    "\n",
    "# Check for time[s] column\n",
    "if 'time[s]' in df.columns:\n",
    "    print(f\"\\n'time[s]' found with {df['time[s]'].isna().sum()} missing values\")\n",
    "    df = df.drop(columns=['time[s]'])\n",
    "    print(f\"New shape: {df.shape}\")\n",
    "\n",
    "print(f\"\\nTimestamp column: '{df.columns[0] if 'time' in df.columns[0].lower() else 'NOT FOUND'}'\")\n",
    "print(f\"Timestamp missing values: {df['timestamp'].isna().sum()}\")\n",
    "\n",
    "# Basic verification\n",
    "assert df.shape[0] == 53199, f\"Row count mismatch: {df.shape[0]} != 53199\"\n",
    "assert 'timestamp' in df.columns, \"Timestamp column not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202c6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: LOAD TAXONOMY AND VERIFY\n",
      "Features to scale: 50\n",
      "All 50 features found in dataframe\n",
      "\n",
      "Columns to use for imputation:\n",
      "  Radio metrics:      10 features\n",
      "  Network QoS:        12 features\n",
      "  Traffic KPIs:       10 features\n",
      "  Vehicle telemetry:  18 features\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 2: LOAD TAXONOMY AND VERIFY\")\n",
    "\n",
    "# Load the taxonomy from Day 1\n",
    "exec(open('column_taxonomy.py').read())\n",
    "\n",
    "# Get features to scale (the 50 continuous features)\n",
    "features_to_scale = []\n",
    "for category in ['radio_metrics', 'network_qos', 'traffic_kpis', 'vehicle_telemetry']:\n",
    "    features_to_scale.extend(column_taxonomy[category])\n",
    "\n",
    "print(f\"Features to scale: {len(features_to_scale)}\")\n",
    "\n",
    "# Verify all features exist in dataframe\n",
    "missing_features = [f for f in features_to_scale if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n  WARNING: These features not in dataframe:\")\n",
    "    for f in missing_features:\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(\"All 50 features found in dataframe\")\n",
    "\n",
    "# Show what we have\n",
    "print(f\"\\nColumns to use for imputation:\")\n",
    "print(f\"  Radio metrics:      {len([f for f in features_to_scale if f in column_taxonomy['radio_metrics']])} features\")\n",
    "print(f\"  Network QoS:        {len([f for f in features_to_scale if f in column_taxonomy['network_qos']])} features\")\n",
    "print(f\"  Traffic KPIs:       {len([f for f in features_to_scale if f in column_taxonomy['traffic_kpis']])} features\")\n",
    "print(f\"  Vehicle telemetry:  {len([f for f in features_to_scale if f in column_taxonomy['vehicle_telemetry']])} features\")\n",
    "\n",
    "# Save features list for later\n",
    "with open('data/processed/features_to_scale.pkl', 'wb') as f:\n",
    "    pickle.dump(features_to_scale, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a05453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: CREATE MISSINGNESS INDICATORS\n",
      "Created 50 missingness indicators\n",
      "\n",
      "Verification:\n",
      "  Feature: serving_cell_snr_1\n",
      "  Original NaN count: 14161\n",
      "  Indicator sum: 14161\n",
      "  Match: True\n",
      "\n",
      "Current dataframe shape: (53199, 147)\n",
      "  Original features: 97\n",
      "  + Missingness indicators: 50\n",
      "  = Total: 147\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 3: CREATE MISSINGNESS INDICATORS\")\n",
    "\n",
    "# Create indicators BEFORE any manipulation\n",
    "# 1 = was missing, 0 = was observed\n",
    "missingness_indicators = []\n",
    "\n",
    "for feature in features_to_scale:\n",
    "    indicator_name = f\"{feature}_was_missing\"\n",
    "    df[indicator_name] = df[feature].isna().astype(int)\n",
    "    missingness_indicators.append(indicator_name)\n",
    "\n",
    "print(f\"Created {len(missingness_indicators)} missingness indicators\")\n",
    "\n",
    "# Verify\n",
    "print(f\"\\nVerification:\")\n",
    "sample_feature = features_to_scale[0]\n",
    "sample_indicator = f\"{sample_feature}_was_missing\"\n",
    "\n",
    "original_missing = df[sample_feature].isna().sum()\n",
    "indicator_count = df[sample_indicator].sum()\n",
    "\n",
    "print(f\"  Feature: {sample_feature}\")\n",
    "print(f\"  Original NaN count: {original_missing}\")\n",
    "print(f\"  Indicator sum: {indicator_count}\")\n",
    "print(f\"  Match: {original_missing == indicator_count}\")\n",
    "\n",
    "assert original_missing == indicator_count, \"Indicator mismatch!\"\n",
    "\n",
    "\n",
    "# Current shape\n",
    "print(f\"\\nCurrent dataframe shape: {df.shape}\")\n",
    "print(f\"  Original features: 97\")\n",
    "print(f\"  + Missingness indicators: {len(missingness_indicators)}\")\n",
    "print(f\"  = Total: {97 + len(missingness_indicators)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57824de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: TIMESTAMP CONVERSION AND SORTING\n",
      "Time range:\n",
      "  Start: 2021-12-14 13:30:49+01:00\n",
      "  End:   2021-12-16 15:07:53+01:00\n",
      "  Duration: 2 days 01:37:04\n",
      "\n",
      "Duplicate timestamps: 0\n",
      "\n",
      "Sampling intervals:\n",
      "  Mean:   0 days 00:00:03.357720215\n",
      "  Median: 0 days 00:00:01\n",
      "  Min:    0 days 00:00:01\n",
      "  Max:    0 days 16:56:32\n",
      "\n",
      "Data sorted by time\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 4: TIMESTAMP CONVERSION AND SORTING\")\n",
    "\n",
    "# Convert to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by time (CRITICAL for temporal split)\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Time range:\")\n",
    "print(f\"  Start: {df['timestamp'].min()}\")\n",
    "print(f\"  End:   {df['timestamp'].max()}\")\n",
    "print(f\"  Duration: {df['timestamp'].max() - df['timestamp'].min()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df['timestamp'].duplicated().sum()\n",
    "print(f\"\\nDuplicate timestamps: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"  Note: Multiple measurements at same timestamp (normal for this type of data)\")\n",
    "\n",
    "# Sampling rate\n",
    "time_diffs = df['timestamp'].diff().dropna()\n",
    "print(f\"\\nSampling intervals:\")\n",
    "print(f\"  Mean:   {time_diffs.mean()}\")\n",
    "print(f\"  Median: {time_diffs.median()}\")\n",
    "print(f\"  Min:    {time_diffs.min()}\")\n",
    "print(f\"  Max:    {time_diffs.max()}\")\n",
    "\n",
    "print(\"\\nData sorted by time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa2eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: BALANCED TEMPORAL SPLIT (OPTION B)\n",
      "Total rows: 53,199\n",
      "Total chunks: 532\n",
      "\n",
      "Chunk distribution:\n",
      "  Train chunks: 372 (69.9%)\n",
      "  Val chunks:   80 (15.0%)\n",
      "  Test chunks:  80 (15.0%)\n",
      "\n",
      "Split sizes:\n",
      "  Train: 37,200 rows (69.9%)\n",
      "  Val:   8,000 rows (15.0%)\n",
      "  Test:  7,999 rows (15.0%)\n",
      "\n",
      "Time ranges:\n",
      "  Train: 2021-12-14 13:32:29+01:00 to 2021-12-16 15:06:14+01:00\n",
      "  Val:   2021-12-14 13:34:09+01:00 to 2021-12-16 15:01:14+01:00\n",
      "  Test:  2021-12-14 13:30:49+01:00 to 2021-12-16 15:07:53+01:00\n",
      "MISSING DATA BALANCE CHECK\n",
      "  Train: 26.16% missing\n",
      "  Val  : 26.60% missing\n",
      "  Test : 27.15% missing\n",
      "\n",
      "Max difference between splits: 1.00%\n",
      "Splits are well-balanced (difference < 5%)\n",
      "\n",
      "Balanced temporal split complete\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 5: BALANCED TEMPORAL SPLIT (OPTION B)\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Strategy: Split by chunks to preserve local temporal patterns\n",
    "# while ensuring balanced missing percentages\n",
    "\n",
    "# Create chunk IDs (group every 100 consecutive rows)\n",
    "df['chunk_id'] = df.index // 100\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Total chunks: {df['chunk_id'].nunique()}\")\n",
    "\n",
    "# Get unique chunk IDs\n",
    "unique_chunks = df['chunk_id'].unique()\n",
    "\n",
    "# Split chunks: 70% train, 15% val, 15% test\n",
    "train_chunks, temp_chunks = train_test_split(\n",
    "    unique_chunks, \n",
    "    test_size=0.30, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_chunks, test_chunks = train_test_split(\n",
    "    temp_chunks, \n",
    "    test_size=0.50,  # 50% of 30% = 15% overall\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nChunk distribution:\")\n",
    "print(f\"  Train chunks: {len(train_chunks)} ({len(train_chunks)/len(unique_chunks)*100:.1f}%)\")\n",
    "print(f\"  Val chunks:   {len(val_chunks)} ({len(val_chunks)/len(unique_chunks)*100:.1f}%)\")\n",
    "print(f\"  Test chunks:  {len(test_chunks)} ({len(test_chunks)/len(unique_chunks)*100:.1f}%)\")\n",
    "\n",
    "# Create splits and sort by time within each split\n",
    "train_df = df[df['chunk_id'].isin(train_chunks)].copy()\n",
    "val_df = df[df['chunk_id'].isin(val_chunks)].copy()\n",
    "test_df = df[df['chunk_id'].isin(test_chunks)].copy()\n",
    "\n",
    "# Sort each split by timestamp\n",
    "train_df = train_df.sort_values('timestamp').reset_index(drop=True)\n",
    "val_df = val_df.sort_values('timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Drop the chunk_id column (no longer needed)\n",
    "train_df = train_df.drop('chunk_id', axis=1)\n",
    "val_df = val_df.drop('chunk_id', axis=1)\n",
    "test_df = test_df.drop('chunk_id', axis=1)\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train: {len(train_df):,} rows ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df):,} rows ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df):,} rows ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Time ranges for each split\n",
    "print(f\"\\nTime ranges:\")\n",
    "print(f\"  Train: {train_df['timestamp'].min()} to {train_df['timestamp'].max()}\")\n",
    "print(f\"  Val:   {val_df['timestamp'].min()} to {val_df['timestamp'].max()}\")\n",
    "print(f\"  Test:  {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "\n",
    "# CRITICAL: Check missing percentages\n",
    "print(\"MISSING DATA BALANCE CHECK\")\n",
    "\n",
    "for name, split_df in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    missing_pct = split_df[features_to_scale].isnull().sum().sum() / split_df[features_to_scale].size * 100\n",
    "    print(f\"  {name:5s}: {missing_pct:.2f}% missing\")\n",
    "\n",
    "# Calculate difference\n",
    "train_missing = train_df[features_to_scale].isnull().sum().sum() / train_df[features_to_scale].size * 100\n",
    "val_missing = val_df[features_to_scale].isnull().sum().sum() / val_df[features_to_scale].size * 100\n",
    "test_missing = test_df[features_to_scale].isnull().sum().sum() / test_df[features_to_scale].size * 100\n",
    "\n",
    "max_diff = max(abs(train_missing - val_missing), \n",
    "               abs(train_missing - test_missing),\n",
    "               abs(val_missing - test_missing))\n",
    "\n",
    "print(f\"\\nMax difference between splits: {max_diff:.2f}%\")\n",
    "\n",
    "if max_diff < 5.0:\n",
    "    print(\"Splits are well-balanced (difference < 5%)\")\n",
    "elif max_diff < 10.0:\n",
    "    print(\"Splits are acceptable (difference < 10%)\")\n",
    "else:\n",
    "    print(\"Splits are imbalanced (difference > 10%)\")\n",
    "    print(\"Consider re-running with different random_state\")\n",
    "\n",
    "print(\"\\nBalanced temporal split complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19652da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: FIT SCALER (TRAINING DATA ONLY)\n",
      "Fitting scaler on training data...\n",
      "  Training samples: 37,200\n",
      "  Features to scale: 50\n",
      "\n",
      "Scaler fitted on training data\n",
      "\n",
      "Scaling parameters (first 5 features):\n",
      "Feature                            Center      Scale\n",
      "serving_cell_snr_1                  13.00       6.80\n",
      "serving_cell_rssi_1                -84.40       7.80\n",
      "serving_cell_rsrq_1                 -9.40       3.40\n",
      "serving_cell_rsrp_1               -115.00      12.80\n",
      "serving_cell_id                      6.00       1.00\n",
      "\n",
      "Scaler verification passed\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 6: FIT SCALER (TRAINING DATA ONLY)\")\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Get training features\n",
    "train_features = train_df[features_to_scale]\n",
    "\n",
    "print(f\"Fitting scaler on training data...\")\n",
    "print(f\"  Training samples: {len(train_features):,}\")\n",
    "print(f\"  Features to scale: {len(features_to_scale)}\")\n",
    "\n",
    "# Fit scaler (RobustScaler handles NaNs automatically)\n",
    "scaler.fit(train_features)\n",
    "\n",
    "print(\"\\nScaler fitted on training data\")\n",
    "\n",
    "# Show scaling parameters for first 5 features\n",
    "print(f\"\\nScaling parameters (first 5 features):\")\n",
    "print(f\"{'Feature':<30s} {'Center':>10s} {'Scale':>10s}\")\n",
    "\n",
    "for i, feature in enumerate(features_to_scale[:5]):\n",
    "    center = scaler.center_[i]\n",
    "    scale = scaler.scale_[i]\n",
    "    print(f\"{feature:<30s} {center:>10.2f} {scale:>10.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "\n",
    "# Verification: Check that scaler was fitted correctly\n",
    "assert hasattr(scaler, 'center_'), \"Scaler not fitted correctly!\"\n",
    "assert len(scaler.center_) == len(features_to_scale), \"Scaler dimension mismatch!\"\n",
    "\n",
    "print(\"\\nScaler verification passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2029f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: APPLY SCALING (PRESERVE NaNs)\n",
      "Scaling train set...\n",
      "Scaling val set...\n",
      "Scaling test set...\n",
      "\n",
      " All splits scaled\n",
      "VERIFICATION 1: NaN PRESERVATION\n",
      "Train: Original NaNs=486,501 | Scaled NaNs=486,501 | ✓\n",
      "Val  : Original NaNs=106,398 | Scaled NaNs=106,398 | ✓\n",
      "Test : Original NaNs=108,601 | Scaled NaNs=108,601 | ✓\n",
      "\n",
      " All NaNs preserved correctly\n",
      "VERIFICATION 2: SCALING EFFECTIVENESS\n",
      "Sample feature: serving_cell_snr_1\n",
      "\n",
      "Original (unscaled):\n",
      "  Mean:      14.0068\n",
      "  Median:    13.0000\n",
      "  Std:        4.1626\n",
      "  Min:        1.5000\n",
      "  Max:       23.8000\n",
      "\n",
      "Scaled:\n",
      "  Mean:       0.1481 (should be ~0)\n",
      "  Median:     0.0000 (should be ~0)\n",
      "  Std:        0.6122\n",
      "  Min:       -1.6912\n",
      "  Max:        1.5882\n",
      "\n",
      " Scaling centered correctly (mean ≈ 0)\n",
      "VERIFICATION 3: SCALED RANGES\n",
      "Checking all 50 features...\n",
      "\n",
      "  17 features have values beyond [-10, 10]:\n",
      "  delay_std_UL                  : [  -1.29, 1170.63]\n",
      "  delay_mean_UL                 : [  -1.00,  994.64]\n",
      "  jitter_UL                     : [  -0.93,  234.84]\n",
      "  delay_std_DL                  : [  -0.74,   42.40]\n",
      "  delay_mean_DL                 : [  -0.94,   67.06]\n",
      "  (This is OK if you have outliers - RobustScaler handles them)\n",
      "VERIFICATION 4: NO DATA LEAKAGE CHECK\n",
      "Sample feature: serving_cell_snr_1\n",
      "  Train range: [  -1.69,    1.59]\n",
      "  Val range:   [  -1.32,    1.47]\n",
      "  Test range:  [  -3.38,    1.56]\n",
      "\n",
      "  Note: Val range within train range (can happen with balanced splits)\n",
      " SCALING COMPLETE AND VERIFIED \n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 7: APPLY SCALING (PRESERVE NaNs)\")\n",
    "\n",
    "def scale_features_preserve_nans(df, scaler, features):\n",
    "    \"\"\"\n",
    "    Scale features while preserving NaN locations\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with data\n",
    "        scaler: Fitted RobustScaler\n",
    "        features: List of features to scale\n",
    "    \n",
    "    Returns:\n",
    "        df_scaled: DataFrame with scaled features, NaNs preserved\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Get the data\n",
    "    data = df[features].values\n",
    "    \n",
    "    # Remember where NaNs are BEFORE scaling\n",
    "    nan_mask = np.isnan(data)\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaled_data = scaler.transform(df[features])\n",
    "    \n",
    "    # Force NaNs back to NaN (sklearn might change them)\n",
    "    scaled_data[nan_mask] = np.nan\n",
    "    \n",
    "    # Put scaled data back into dataframe\n",
    "    df_scaled[features] = scaled_data\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "# Apply scaling to all three splits\n",
    "print(\"Scaling train set...\")\n",
    "train_df_scaled = scale_features_preserve_nans(train_df, scaler, features_to_scale)\n",
    "\n",
    "print(\"Scaling val set...\")\n",
    "val_df_scaled = scale_features_preserve_nans(val_df, scaler, features_to_scale)\n",
    "\n",
    "print(\"Scaling test set...\")\n",
    "test_df_scaled = scale_features_preserve_nans(test_df, scaler, features_to_scale)\n",
    "\n",
    "print(\"\\n All splits scaled\")\n",
    "\n",
    "\n",
    "# VERIFICATION 1: NaN PRESERVATION\n",
    "\n",
    "print(\"VERIFICATION 1: NaN PRESERVATION\")\n",
    "\n",
    "\n",
    "for name, original, scaled in [\n",
    "    ('Train', train_df, train_df_scaled),\n",
    "    ('Val', val_df, val_df_scaled),\n",
    "    ('Test', test_df, test_df_scaled)\n",
    "]:\n",
    "    original_nans = original[features_to_scale].isnull().sum().sum()\n",
    "    scaled_nans = scaled[features_to_scale].isnull().sum().sum()\n",
    "    match = \"✓\" if original_nans == scaled_nans else \"✗\"\n",
    "    \n",
    "    print(f\"{name:5s}: Original NaNs={original_nans:>6,} | Scaled NaNs={scaled_nans:>6,} | {match}\")\n",
    "    \n",
    "    # Assert they match\n",
    "    assert original_nans == scaled_nans, f\"{name}: NaN count changed after scaling!\"\n",
    "\n",
    "print(\"\\n All NaNs preserved correctly\")\n",
    "\n",
    "\n",
    "# VERIFICATION 2: SCALING WORKED\n",
    "\n",
    "print(\"VERIFICATION 2: SCALING EFFECTIVENESS\")\n",
    "\n",
    "# Check first feature as example\n",
    "sample_feature = features_to_scale[0]\n",
    "print(f\"Sample feature: {sample_feature}\")\n",
    "\n",
    "# Training data - observed values only\n",
    "train_original = train_df[sample_feature].dropna()\n",
    "train_scaled = train_df_scaled[sample_feature].dropna()\n",
    "\n",
    "print(f\"\\nOriginal (unscaled):\")\n",
    "print(f\"  Mean:   {train_original.mean():10.4f}\")\n",
    "print(f\"  Median: {train_original.median():10.4f}\")\n",
    "print(f\"  Std:    {train_original.std():10.4f}\")\n",
    "print(f\"  Min:    {train_original.min():10.4f}\")\n",
    "print(f\"  Max:    {train_original.max():10.4f}\")\n",
    "\n",
    "print(f\"\\nScaled:\")\n",
    "print(f\"  Mean:   {train_scaled.mean():10.4f} (should be ~0)\")\n",
    "print(f\"  Median: {train_scaled.median():10.4f} (should be ~0)\")\n",
    "print(f\"  Std:    {train_scaled.std():10.4f}\")\n",
    "print(f\"  Min:    {train_scaled.min():10.4f}\")\n",
    "print(f\"  Max:    {train_scaled.max():10.4f}\")\n",
    "\n",
    "# Check if mean is close to 0 (within reason)\n",
    "if abs(train_scaled.mean()) < 0.5:\n",
    "    print(\"\\n Scaling centered correctly (mean ≈ 0)\")\n",
    "else:\n",
    "    print(f\"\\n  Warning: Mean is {train_scaled.mean():.4f}, expected ~0\")\n",
    "\n",
    "# VERIFICATION 3: RANGE CHECK\n",
    "\n",
    "print(\"VERIFICATION 3: SCALED RANGES\")\n",
    "\n",
    "\n",
    "print(f\"Checking all {len(features_to_scale)} features...\")\n",
    "\n",
    "# Check ranges for all features\n",
    "extreme_features = []\n",
    "\n",
    "for feature in features_to_scale:\n",
    "    scaled_vals = train_df_scaled[feature].dropna()\n",
    "    if len(scaled_vals) > 0:\n",
    "        min_val = scaled_vals.min()\n",
    "        max_val = scaled_vals.max()\n",
    "        \n",
    "        # Flag if range is unusually large (might indicate scaling issue)\n",
    "        if abs(min_val) > 10 or abs(max_val) > 10:\n",
    "            extreme_features.append({\n",
    "                'feature': feature,\n",
    "                'min': min_val,\n",
    "                'max': max_val\n",
    "            })\n",
    "\n",
    "if extreme_features:\n",
    "    print(f\"\\n  {len(extreme_features)} features have values beyond [-10, 10]:\")\n",
    "    for item in extreme_features[:5]:  # Show first 5\n",
    "        print(f\"  {item['feature']:30s}: [{item['min']:7.2f}, {item['max']:7.2f}]\")\n",
    "    print(\"  (This is OK if you have outliers - RobustScaler handles them)\")\n",
    "else:\n",
    "    print(\"\\n All features in reasonable range\")\n",
    "\n",
    "\n",
    "# VERIFICATION 4: NO DATA LEAKAGE\n",
    "\n",
    "\n",
    "print(\"VERIFICATION 4: NO DATA LEAKAGE CHECK\")\n",
    "\n",
    "\n",
    "# Scaler should only know about training data\n",
    "# Val and test should have different ranges\n",
    "\n",
    "sample_feature = features_to_scale[0]\n",
    "\n",
    "train_range = (train_df_scaled[sample_feature].min(), \n",
    "               train_df_scaled[sample_feature].max())\n",
    "val_range = (val_df_scaled[sample_feature].min(), \n",
    "             val_df_scaled[sample_feature].max())\n",
    "test_range = (test_df_scaled[sample_feature].min(), \n",
    "              test_df_scaled[sample_feature].max())\n",
    "\n",
    "print(f\"Sample feature: {sample_feature}\")\n",
    "print(f\"  Train range: [{train_range[0]:7.2f}, {train_range[1]:7.2f}]\")\n",
    "print(f\"  Val range:   [{val_range[0]:7.2f}, {val_range[1]:7.2f}]\")\n",
    "print(f\"  Test range:  [{test_range[0]:7.2f}, {test_range[1]:7.2f}]\")\n",
    "\n",
    "# Val/test can have values outside train range (that's good!)\n",
    "if val_range[0] < train_range[0] or val_range[1] > train_range[1]:\n",
    "    print(\"\\nVal has values outside train range (no data leakage)\")\n",
    "else:\n",
    "    print(\"\\n  Note: Val range within train range (can happen with balanced splits)\")\n",
    "\n",
    "print(\" SCALING COMPLETE AND VERIFIED \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388463c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 8: SAVE PROCESSED DATASETS\n",
      "Saving datasets...\n",
      "   train.csv\n",
      "   val.csv\n",
      " test.csv\n",
      " metadata.pkl\n",
      "SAVED FILES SUMMARY\n",
      "\n",
      "Datasets:\n",
      "  train.csv:    37,200 rows × 147 cols\n",
      "  val.csv:       8,000 rows × 147 cols\n",
      "  test.csv:      7,999 rows × 147 cols\n",
      "\n",
      "Metadata includes:\n",
      "  - 50 features to scale\n",
      "  - 50 missingness indicators\n",
      "  - Time ranges for each split\n",
      "  - Missing percentages: Train=26.16%, Val=26.60%, Test=27.15%\n",
      "\n",
      " All datasets and metadata saved to data/processed/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"STEP 8: SAVE PROCESSED DATASETS\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# Save the scaled datasets\n",
    "print(\"Saving datasets...\")\n",
    "\n",
    "train_df_scaled.to_csv('data/processed/train.csv', index=False)\n",
    "print(\"   train.csv\")\n",
    "\n",
    "val_df_scaled.to_csv('data/processed/val.csv', index=False)\n",
    "print(\"   val.csv\")\n",
    "\n",
    "test_df_scaled.to_csv('data/processed/test.csv', index=False)\n",
    "print(\" test.csv\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'features_to_scale': features_to_scale,\n",
    "    'missingness_indicators': missingness_indicators,\n",
    "    'column_taxonomy': column_taxonomy,\n",
    "    \n",
    "    # Split sizes\n",
    "    'train_size': len(train_df_scaled),\n",
    "    'val_size': len(val_df_scaled),\n",
    "    'test_size': len(test_df_scaled),\n",
    "    \n",
    "    # Time ranges\n",
    "    'train_time_range': (str(train_df_scaled['timestamp'].min()), \n",
    "                         str(train_df_scaled['timestamp'].max())),\n",
    "    'val_time_range': (str(val_df_scaled['timestamp'].min()), \n",
    "                       str(val_df_scaled['timestamp'].max())),\n",
    "    'test_time_range': (str(test_df_scaled['timestamp'].min()), \n",
    "                        str(test_df_scaled['timestamp'].max())),\n",
    "    \n",
    "    # Missing percentages\n",
    "    'train_missing_pct': train_df_scaled[features_to_scale].isnull().sum().sum() / train_df_scaled[features_to_scale].size * 100,\n",
    "    'val_missing_pct': val_df_scaled[features_to_scale].isnull().sum().sum() / val_df_scaled[features_to_scale].size * 100,\n",
    "    'test_missing_pct': test_df_scaled[features_to_scale].isnull().sum().sum() / test_df_scaled[features_to_scale].size * 100,\n",
    "}\n",
    "\n",
    "with open('data/processed/metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\" metadata.pkl\")\n",
    "\n",
    "# Display summary\n",
    "print(\"SAVED FILES SUMMARY\")\n",
    "\n",
    "print(f\"\\nDatasets:\")\n",
    "print(f\"  train.csv:    {len(train_df_scaled):>6,} rows × {len(train_df_scaled.columns):>3} cols\")\n",
    "print(f\"  val.csv:      {len(val_df_scaled):>6,} rows × {len(val_df_scaled.columns):>3} cols\")\n",
    "print(f\"  test.csv:     {len(test_df_scaled):>6,} rows × {len(test_df_scaled.columns):>3} cols\")\n",
    "\n",
    "print(f\"\\nMetadata includes:\")\n",
    "print(f\"  - {len(features_to_scale)} features to scale\")\n",
    "print(f\"  - {len(missingness_indicators)} missingness indicators\")\n",
    "print(f\"  - Time ranges for each split\")\n",
    "print(f\"  - Missing percentages: Train={metadata['train_missing_pct']:.2f}%, Val={metadata['val_missing_pct']:.2f}%, Test={metadata['test_missing_pct']:.2f}%\")\n",
    "\n",
    "print(\"\\n All datasets and metadata saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6695898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 9: CREATE ARTIFICIAL MASKS FOR EVALUATION\n",
      "VALIDATION SET\n",
      "  Mask ratio: 15% of observed values\n",
      "  Random seed: 42\n",
      "\n",
      "Artificially masked validation set\n",
      "  Ground truth entries: 44,020\n",
      "  Coverage: 11.00% of val data\n",
      "  Original NaNs: 106,398\n",
      "  After masking: 150,418\n",
      "  Increase: 44,020 (should match ground truth size)\n",
      "TEST SET\n",
      "  Mask ratio: 15% of observed values\n",
      "  Random seed: 123\n",
      "\n",
      " Artificially masked test set\n",
      "  Ground truth entries: 43,669\n",
      "  Coverage: 10.92% of test data\n",
      "  Original NaNs: 108,601\n",
      "  After masking: 152,270\n",
      "  Increase: 43,669 (should match ground truth size)\n",
      "SAVING MASKED DATASETS AND GROUND TRUTH\n",
      "  val_masked.csv\n",
      "  test_masked.csv\n",
      "  val_ground_truth.pkl\n",
      "  test_ground_truth.pkl\n",
      "PREPROCESSING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 9: CREATE ARTIFICIAL MASKS FOR EVALUATION\")\n",
    "\n",
    "def create_artificial_masks(df, features, mask_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Artificially mask observed values for evaluation\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with scaled data\n",
    "        features: List of features to mask\n",
    "        mask_ratio: Proportion of OBSERVED values to mask (0.15 = 15%)\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        df_masked: DataFrame with additional masks applied\n",
    "        ground_truth: Dict {(row_idx, feature): original_value}\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    df_masked = df.copy()\n",
    "    ground_truth = {}\n",
    "    \n",
    "    print(f\"  Mask ratio: {mask_ratio*100:.0f}% of observed values\")\n",
    "    print(f\"  Random seed: {seed}\")\n",
    "    \n",
    "    for feature in features:\n",
    "        # Find OBSERVED values (not originally missing)\n",
    "        indicator_col = f\"{feature}_was_missing\"\n",
    "        \n",
    "        if indicator_col in df.columns:\n",
    "            # observed = indicator is 0 AND value is not NaN\n",
    "            observed_mask = (df[indicator_col] == 0) & df[feature].notna()\n",
    "        else:\n",
    "            # No indicator, just check not NaN\n",
    "            observed_mask = df[feature].notna()\n",
    "        \n",
    "        observed_indices = df[observed_mask].index.tolist()\n",
    "        \n",
    "        if len(observed_indices) == 0:\n",
    "            continue  # No observed values\n",
    "        \n",
    "        # Randomly select some to mask\n",
    "        n_to_mask = int(len(observed_indices) * mask_ratio)\n",
    "        \n",
    "        if n_to_mask == 0:\n",
    "            continue\n",
    "        \n",
    "        masked_indices = np.random.choice(\n",
    "            observed_indices,\n",
    "            size=n_to_mask,\n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Store ground truth BEFORE masking\n",
    "        for idx in masked_indices:\n",
    "            ground_truth[(idx, feature)] = df.loc[idx, feature]\n",
    "        \n",
    "        # Apply artificial mask (set to NaN)\n",
    "        df_masked.loc[masked_indices, feature] = np.nan\n",
    "    \n",
    "    return df_masked, ground_truth\n",
    "\n",
    "\n",
    "# Create masks for VALIDATION set\n",
    "print(\"VALIDATION SET\")\n",
    "\n",
    "\n",
    "val_df_masked, val_ground_truth = create_artificial_masks(\n",
    "    val_df_scaled,\n",
    "    features_to_scale,\n",
    "    mask_ratio=0.15,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nArtificially masked validation set\")\n",
    "print(f\"  Ground truth entries: {len(val_ground_truth):,}\")\n",
    "print(f\"  Coverage: {len(val_ground_truth) / (len(val_df_scaled) * len(features_to_scale)) * 100:.2f}% of val data\")\n",
    "\n",
    "# Check NaN increase\n",
    "val_original_nans = val_df_scaled[features_to_scale].isnull().sum().sum()\n",
    "val_masked_nans = val_df_masked[features_to_scale].isnull().sum().sum()\n",
    "print(f\"  Original NaNs: {val_original_nans:,}\")\n",
    "print(f\"  After masking: {val_masked_nans:,}\")\n",
    "print(f\"  Increase: {val_masked_nans - val_original_nans:,} (should match ground truth size)\")\n",
    "\n",
    "assert len(val_ground_truth) == (val_masked_nans - val_original_nans), \"Mismatch in val masking!\"\n",
    "\n",
    "\n",
    "# Create masks for TEST set\n",
    "\n",
    "\n",
    "print(\"TEST SET\")\n",
    "\n",
    "\n",
    "test_df_masked, test_ground_truth = create_artificial_masks(\n",
    "    test_df_scaled,\n",
    "    features_to_scale,\n",
    "    mask_ratio=0.15,\n",
    "    seed=123  # Different seed for test\n",
    ")\n",
    "\n",
    "print(f\"\\n Artificially masked test set\")\n",
    "print(f\"  Ground truth entries: {len(test_ground_truth):,}\")\n",
    "print(f\"  Coverage: {len(test_ground_truth) / (len(test_df_scaled) * len(features_to_scale)) * 100:.2f}% of test data\")\n",
    "\n",
    "# Check NaN increase\n",
    "test_original_nans = test_df_scaled[features_to_scale].isnull().sum().sum()\n",
    "test_masked_nans = test_df_masked[features_to_scale].isnull().sum().sum()\n",
    "print(f\"  Original NaNs: {test_original_nans:,}\")\n",
    "print(f\"  After masking: {test_masked_nans:,}\")\n",
    "print(f\"  Increase: {test_masked_nans - test_original_nans:,} (should match ground truth size)\")\n",
    "\n",
    "assert len(test_ground_truth) == (test_masked_nans - test_original_nans), \"Mismatch in test masking!\"\n",
    "\n",
    "\n",
    "# Save everything\n",
    "\n",
    "\n",
    "print(\"SAVING MASKED DATASETS AND GROUND TRUTH\")\n",
    "\n",
    "\n",
    "# Save masked datasets\n",
    "val_df_masked.to_csv('data/processed/val_masked.csv', index=False)\n",
    "print(\"  val_masked.csv\")\n",
    "\n",
    "test_df_masked.to_csv('data/processed/test_masked.csv', index=False)\n",
    "print(\"  test_masked.csv\")\n",
    "\n",
    "# Save ground truth\n",
    "with open('data/processed/val_ground_truth.pkl', 'wb') as f:\n",
    "    pickle.dump(val_ground_truth, f)\n",
    "print(\"  val_ground_truth.pkl\")\n",
    "\n",
    "with open('data/processed/test_ground_truth.pkl', 'wb') as f:\n",
    "    pickle.dump(test_ground_truth, f)\n",
    "print(\"  test_ground_truth.pkl\")\n",
    "\n",
    "\n",
    "print(\"PREPROCESSING COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b30f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
